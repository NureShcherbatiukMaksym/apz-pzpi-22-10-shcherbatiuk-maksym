МІНІСТЕРСТВО ОСВІТИ І НАУКИ УКРАЇНИ

ХАРКІВСЬКИЙ НАЦІОНАЛЬНИЙ
УНІВЕРСИТЕТ РАДІОЕЛЕКТРОНІКИ

Кафедра «Програмна інженерія»


ЗВІТ
до лабораторної роботи №4 з дисципліни
«Аналіз та рефакторинг коду»
На тему: «Маштабування бекенда»



Виконав:                                              		    Перевірив:
ст. гр. ПЗПІ-22-10 				         	    ас. кафедри ПІ 
Щербатюк Максим Олександрович 		    Дашенков Дмитро Сергійович











Харків 2025
     4.1 Опис стратегії маштабування сисетми
     Стратегія масштабування моєї системи базується на горизонтальному масштабуванні бекенд-сервісу Node.js, що працює за допомогою кластерного менеджера PM2, та використанні зворотного проксі та балансувальника навантаження Nginx.
     Горизонтальне масштабування: Замість того, щоб збільшувати потужність одного сервера (вертикальне масштабування, наприклад, додаючи більше CPU/RAM), ми запускаємо кілька незалежних копій (екземплярів) вашого Node.js застосунку. Кожен екземпляр працює як окремий процес, використовуючи власні ресурси, що дозволяє задіяти всі доступні ядра процесора.
     PM2 Cluster Mode: PM2 дозволяє легко запускати Node.js додатки в кластерному режимі, автоматично створюючи та керуючи кількома екземплярами вашого застосунку, розподіляючи між ними вхідні з'єднання. Це гарантує, що бекенд може повною мірою використовувати багатоядерні процесори.
     Nginx як балансувальник навантаження: Nginx діє як єдина точка входу для всіх запитів клієнтів (фронтенду). Замість того, щоб клієнт звертався безпосередньо до одного з екземплярів Node.js, Nginx перехоплює запит і, використовуючи алгоритми балансування навантаження (за замовчуванням round-robin), рівномірно розподіляє ці запити між доступними бекенд-екземплярами Node.js. Це забезпечує ефективне використання ресурсів усіх працюючих екземплярів та підвищує відмовостійкість.
     Redis для сесій та Socket.IO адаптера: Використання Redis як сховища для сесій (express-session з connect-redis) та адаптера для Socket.IO (@socket.io/redis-adapter) є критично важливим для горизонтального масштабування. Це дозволяє екземплярам Node.js ділитися станом сесій (незалежно від того, який екземпляр обробив попередній запит користувача) та забезпечує доставку повідомлень Socket.IO всім підключеним клієнтам, незалежно від того, до якого екземпляра вони підключені. Це вирішує проблему "липких сесій" та дозволяє кластеру працювати як єдине ціле.
     4.2 Опис технічних рішень, які роблять маштабування можливим
     PM2 (Process Manager 2):
     Cluster Mode (exec_mode: 'cluster'): Запускає кілька копій (instances: "max") застосунку, щоб повною мірою використовувати всі ядра процесора.
     Динамічні порти (increment_var: 'PORT'): Кожен екземпляр Node.js запускається на унікальному, послідовно збільшуваному порту (наприклад, 5001, 5002, 5003 і т.д.), починаючи з базового порту, зазначеного в ecosystem.config.js. Це дозволяє Nginx звертатися до кожного екземпляра окремо.
     Автоматичний перезапуск (autorestart: true): PM2 автоматично перезапускає будь-який екземпляр, який аварійно завершив роботу, підвищуючи стабільність та доступність системи.
     Моніторинг (pm2 monit): Надає інструменти для відстеження використання CPU та пам'яті кожним екземпляром, що є критично важливим для виявлення вузьких місць.
     Nginx:
     Зворотний проксі: Приймає всі вхідні запити на єдиному порті (наприклад, 5000) і перенаправляє їх до бекенд-серверів.
     Балансування навантаження (upstream backend_servers): Містить список усіх бекенд-екземплярів Node.js (зазначених за їхніми портами, наприклад, localhost:5001, localhost:5002 і т.д.). Nginx розподіляє запити між ними за алгоритмом round-robin (по черзі), забезпечуючи рівномірний розподіл навантаження.
     Таймаути (proxy_read_timeout, proxy_connect_timeout, proxy_send_timeout): Налаштування таймаутів в Nginx дозволяє керувати часом очікування відповіді від бекенду. Це допомагає запобігти "зависанню" клієнтів, якщо бекенд тимчасово перевантажений або повільний.
     Redis (для сесій та Socket.IO):
     express-session з connect-redis: Зберігає дані сесій користувачів у Redis, а не в пам'яті окремих екземплярів Node.js. Це гарантує, що користувач залишається автентифікованим незалежно від того, який екземпляр обробив його запит, що є обов'язковим для горизонтального масштабування.
     @socket.io/redis-adapter: Дозволяє всім екземплярам Socket.IO (які працюють на різних портах) спілкуватися через Redis. Це дозволяє надсилати повідомлення всім підключеним клієнтам, навіть якщо вони підключені до різних екземплярів, і підтримувати синхронізацію в режимі реального часу в кластерному середовищі.
     
     4.3 Аналіз вузьких місць - які саме ресурси вичерпуються першими при навантаженні
     Перед проведенням навантажувальних тестів було ідентифіковано кілька потенційних вузьких місць у системі, які могли б першими вичерпувати свої ресурси при зростанні навантаження. Ці вузькі місця пов'язані як з архітектурою самого застосунку та його взаємодією з базою даних, так і з особливостями технологій, що використовуються.
     4.3.1. Інтенсивна взаємодія з базою даних: Проблема "N+1" запитів
     Одним з найкритичніших потенційних вузьких місць була ідентифікована функція отримання точок поля з вимірами (getPointsWithLatestMeasurements). Її поточна реалізація передбачала отримання всіх точок для поля, а потім для кожної такої точки – виконання окремого запиту до бази даних для вибірки її вимірювань (Measurement.findAll). Це класичний шаблон "N+1" запитів, де N – це кількість точок на полі.
• Очікуваний вплив: Кожен такий HTTP-запит до бекенду, залежно від розміру поля, міг би генерувати сотні або навіть тисячі індивідуальних запитів до бази даних. Це призводить до: 
o Значної латентності: Час, необхідний на встановлення та закриття з'єднань з БД для кожного мікро-запиту, а також на мережеву передачу даних, суттєво накопичується.
o Вичерпання пулу з'єднань: Сервер застосунку може швидко вичерпати доступні з'єднання до БД.
o Навантаження на БД: База даних буде перевантажена обробкою великої кількості дрібних, але частих запитів, що споживає її CPU, пам'ять та дискові операції.
o Блокування Event Loop (для Node.js): Хоча Node.js є асинхронним, операції введення/виведення (такі як запити до БД) все одно займають час. Якщо їх багато і вони виконуються послідовно в межах одного запиту, це може "засмічувати" Event Loop, перешкоджаючи обробці нових вхідних HTTP-запитів.

     4.3.2. Обчислювальна складність генерації точок поля:
     Функція generateMeasurementPoints, яка використовується при створенні поля, включає геопросторові обчислення (Turf.js) для визначення точок вимірювання в межах заданої геозони. Ці операції є інтенсивними для CPU, особливо для великих полів з високою щільністю точок.

     4.3.3. Синхронізація стану та обмін повідомленнями в кластерному середовищі (вебсокети, сесії):
     При масштабуванні Node.js застосунків до кількох інстансів (процесів/потоків), виникає проблема підтримки спільного стану. Це стосується сесій користувачів (щоб користувач не "вилітав" при зверненні до іншого інстансу) та обміну повідомленнями в реальному часі через вебсокети (щоб повідомлення доходили до всіх підключених клієнтів, незалежно від інстанса, до якого вони підключені). Якщо ці механізми не вирішені, кожен інстанс матиме свій ізольований стан, що порушить функціональність системи.
• Очікуваний вплив: Без належної синхронізації, масштабований застосунок не зможе коректно працювати, навіть якщо ресурси процесора та пам'яті будуть доступні. Це проявлятиметься як неможливість підтримувати сесії, втрата повідомлень у реальному часі, тощо.
• Рішення та підтвердження: Цю потенційну проблему було вирішено архітектурно до проведення навантажувальних тестів, тому вона не проявилася як вузьке місце під час тестування: 
o Сесії: Використання RedisStore для express-session дозволило централізувати зберігання сесій користувачів у Redis, забезпечуючи доступність стану сесії для всіх інстансів бекенду.
o Вебсокети: Інтеграція Redis Adapter для Socket.IO (@socket.io/redis-adapter) дозволила всім інстансам Node.js обмінюватися повідомленнями через централізований Redis-брокер, гарантуючи, що клієнти отримують повідомлення незалежно від того, до якого інстансу вони підключені.
o Завдяки цим рішенням, проблема синхронізації стану не стала вузьким місцем під час навантажувального тестування, дозволяючи системі ефективно використовувати всі 16 інстансів.
     
     
     4.4 Опис навантажувальних тестів з ілюстрацією зв’язку між масштабуванням і витримуваним навантаженням
     Першим тестом до масштабування буде надсилання запиту GET на отримання простого повідомлення. У налаштуваннях запиту, рисунок 1, я вказав, що цей запит будуть підняті 6 користувачів за секунду, в результаті кожний має надіслати цей запит 150 раз.
     

Рисунок 1 – Перший тест до масштабування

На рисунку 2 показане максимальне навантаження на процесор, яке було під час виконання цього тесту.

Рисунок 2 – Навантаження на процесор

     На рисунку 3 продемонстрований результат виконання цього тесту з, у результаті було надіслано 900 запитів з 0% помилок, а на рисунку 4 час виконання цього тесту.
     

Рисунок 3 – Загальні результати тесту


Рисунок 4 – час виконання тесту

     Саме цей запит виявився найбільш вимогливим і був основним вузьким місцем до оптимізації. Вся його складність полягає у множинних зверненнях до бази даних. Функція спочатку отримує всі точки для поля (MeasurementPoint.findAll), а потім для кожної окремої точки виконує ще один запит до бази даних (Measurement.findAll) для отримання її вимірювань. Це є класичним прикладом "N+1" проблеми запитів до БД, де N – це кількість точок на полі. Якщо поле містить, скажімо, 500 точок, то один такий HTTP-запит призводить до 1 (для точок) + 500 (для вимірювань) = 501 окремого запиту до бази даних.
     У налаштуваннях запиту, рисунок 5, я вказав, що цей запит будуть виконувати 3 користувача з проміжком 2 секунди, в результаті кожний має надіслати цей запит 5 раз. 
     

Рисунок 5 – Другий тест до масштабування

     На рисунку 6 продемонстровані результати виконання тесту, в ході тестування було 2 невдалих запити, рисунок 7, з помилкою 502 Bad Gateway, у даному контексті це є прямим підтвердженням того, що мій Node.js бекенд, працюючи в однопотоковому режимі, не може впоратися з навантаженням, яке створює навіть невелика кількість "важких" запитів з "N+1" проблемою до бази даних.
 
Рисунок 6 – Результати тесту

Рисунок 7 – Запити з помилкою 502

На рисунку 8 бачимо скільки ресурсу CPU займав цей тест, а на рисунку 9 час виконання.


Рисунок 8 – Навантаження на процесор


Рисунок 9 – Час виконання тесту


     А тепер творимо тест на надсилання POST запиту на створення поля, тут буде 5 користувачів проміжком в 4 секунди і де кожний має надіслати 60 запитів, рисунок 10.

Рисунок 10 – Третій тест до масштабування

      На рисунку 11 продемонстровано використання CPU під час тесту.


Рисунок 11 –  Навантаження на процесор

     На рисунку 12 продемонстровано результати тестування, в результаті чого ми виконали, в однопоточному режимі до масштабування, 300 запитів на створення поля з генерацією точок на ньому, і у нас не виникало жодної помилки, невідмінну від попереднього тесту.


Рисунок 12 – Результати тесту

     На рисунку 13 зображено час виконання цього тесту який зайняв менше часу ніж другий тест.


Рисунок 13 – Час виконання тесту


     Тепер масштабуємо сервер, а саме створимо стільки екземплярів скільки може наш процесор, рисунок 14.


Рисунок 14 – Запуск сервера в 16 екземплярів

     Тепер виконаємо перший тест збільшивши кількість запитів у 2 рази. На рисунку 15 зображено оновлені налаштування тесту.


Рисунок 15  – Налаштування тесту

     На рисунку 16 бачимо час виконання цього тесту, він виконався за 0,2 секунди що вже набагато швидше ніж до масштабування сервера, а на рисунку 17 продемонстровано результати виконання з яких ми бачимо що у нас виконалося 1800 запитів з 0% помилок.


Рисунок 16 – Час виконання тесту


Рисунок 17 – Результати виконання тесту

     Тепер збільшимо у 2 рази кількість запитів у 2 тесті, подивимося чи вдалося за допомогою масштабування уникнути помилки пов’язаної із затримкою відповіді, рисунок 18.




Рисунок 18 – Налаштування тесту

     На рисунку 19 зображено як використовувалися ресурси процесу під час виконання цього тесту.


Рисунок 19 – Навантаження на процесор

     На рисунку 20 зображений результат виконання тесту, а на рисунку 21 час виконання, з них ми бачимо, що з масштабуванням у нас успішно виконалися 30 складних запитів за 3 хвилини 41 секунду, у той час як до масштабування у нас цей тест на 15 запитів виконався з двома помилками за 6 хвилин 9 секунд.
     
 
Рисунок 20 – Результати виконання тесту


Рисунок 21 – Час виконання тесту
     Однак, наступного разу, коли я виконував цей тест, неочікувано з’явилася помилка від самого JMerter, рисунок 22, вона пов’язана з переповненням відведеної пам’яті для програми у наслідок виконання такого складного запиту, тобто проблема перейшла вже на клієнтську сторону.


Рисунок 22 – Помилка від JMeter

     І тепер останній, третій, тест. Тут ми також збільшили кількість виконуваних запитів, рисунок 23.


Рисунок 23 – Налаштування тесту

     З рисунку 24, ми бачимо, що масштабування у нас дійсно працює і навантаження на процесор розподіляється між всіма екземплярами сервера.


Рисунок 24 – Навантаження на процесор

     У результаті, на рисунку 25, ми бачимо успішно-виконані 600 запитів без жодної помилки, а на рисунку 26 бачимо, що виконання цих запитів було витрачено всього 21 секунду, коли на вдвічі меншу кількість запитів до масштабування ми витратили 4 хвилини 23 секунди.


Рисунок 25 – Результати виконання тесту


Рисунок 26 – Час виконання тесту

     Результати навантажувальних тестів, проведених за допомогою Apache JMeter, підтвердили ці гіпотези. Зокрема:
• Навіть невелика кількість запитів до неоптимізованого методу getPointsWithLatestMeasurements призводила до значно більшої затримки та вичерпання ресурсів бекенду (а в однопотоковому режимі - до 502 Bad Gateway), ніж значно більша кількість запитів на створення полів. Це довело, що саме велика кількість звернень до бази даних, спричинена "N+1" проблемою, є ключовим вузьким місцем, що вичерпує час на очікування та ресурси на обробку.
• Масштабування до 16 інстансів дозволило бекенду ефективніше справлятися з навантаженням, переносячи проблему на іншу ланку - клієнтську частину (JMeter вичерпував пам'ять, намагаючись обробити величезні відповіді). Це ще раз підкреслило, що надмірний обсяг даних, що передається, є суттєвою проблемою, незалежно від кількості інстансів бекенду.

